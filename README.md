# Crop-Image-Classification (AIcup 2022 in Taiwan)
[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/drive/15kOuZZaUoDG33LCQCy-qHHHROab0ViiZ?usp=sharing) 

æˆ‘åœ‹è¾²åœ°ç¯„åœå»£æ³›ï¼Œä½†åˆ†ä½ˆç ´ç¢ï¼Œé€ æˆæ”¶é›†è³‡æºçš„äººåŠ›å’Œæ™‚é–“æˆæœ¬æ¥µé«˜ï¼Œä¸”è¾²æ¥­é ˜åŸŸç›¸å°ç¼ºä¹AIæŠ€è¡“ï¼Œå› æ­¤æœ¬å¯¦ä½œå°‡æœƒæŠŠå¤§é‡å·²æ”¶é›†ä¸¦æ¨™ä½éçš„è¾²ä½œç‰©é€²è¡Œåˆ†é¡å’Œé æ¸¬ã€‚

# Dataset
![](doc/image/crop_data.png)

- `è³‡æ–™å…§å®¹`: ç¾åœ°ä½œç‰©èª¿æŸ¥å½±åƒï¼ŒåŒ…æ‹¬æ‹æ”ä¸è‰¯å½±åƒï¼Œä¾‹å¦‚ï¼šæˆ¿å±‹ã€è»Šè¼›ã€è¾²æ©Ÿå…·ã€æ¨¡ç³Šç•«é¢ç­‰
- `æä¾›å–®ä½`: è¡Œæ”¿é™¢è¾²æ¥­å§”å“¡æœƒ
- `å½±åƒåˆ†é¡`: å«éä½œç‰©å…±33é¡
- `è³‡æ–™æ•¸é‡`: ç¸½è¨ˆ10è¬å¼µä»¥ä¸Š
- `å½±åƒè§£æåº¦`: æœ€å°1280x720 ; æœ€å¤§ 4000x3000
- `æª”æ¡ˆå¤§å°`: ç¸½è¨ˆç´„ 170 GB

# Problem
## 1. æº–å¿ƒå¯ç”¨æ€§
æº–å¿ƒç‚ºå”åŠ©å°ˆå®¶åˆ¤æ–·ä½œç‰©ä¹‹ä¾æ“šï¼Œä½†æº–å¿ƒä¹Ÿå¯èƒ½ç”¢ç”Ÿåç§»ã€‚å…¶ä¸­éä¸­å¿ƒçš„æº–å¿ƒæ¨™è¨˜æœ‰ 22 %ã€‚å…¶ä¸­åªæœ‰ 0.5 % è³‡æ–™æº–å¿ƒåç§»ä¸­å¿ƒè¶…é 100(å·®ä¸å¤šæº–å¿ƒå¤§å°)ã€‚ä¸”å¹¾ä¹å…¨éƒ¨åç§»éƒ½æ˜¯åœ¨ Y è»¸ã€‚
ä¸‹åœ–å¯ä»¥çœ‹åˆ°æº–å¿ƒæ¨™è¨˜éŒ¯èª¤çš„å•é¡Œï¼Œå› æ­¤ç¨®ç…§ç‰‡ä½”æ¥µå°‘æ•¸ï¼Œæ‰€ä»¥å…ˆå¿½ç•¥ã€‚æˆ‘å€‘åˆæ­¥ä½œæ³•æ˜¯ä»¥æº–å¿ƒç‚ºåŸºæº–å¾€å¤–å–å¤ å¤§çš„ç¯„åœï¼Œåªè¦ç…§ç‰‡ä¸­æœ‰åŒ…å«åˆ°æº–å¿ƒå’Œå‘¨é­ä¸€å®šç¯„åœçš„ä½œç‰©å°±å¥½ã€‚
![](doc/fig/mark.png)

## 2. è§£æåº¦ & æª”æ¡ˆå¤§å°
ç…§ç‰‡æœ¬èº«çš„è§£æåº¦å¤§å°æœƒå½±éŸ¿æ•´å€‹æ¨¡å‹è¨“ç·´çš„é›£åº¦ï¼Œè§£æåº¦è¶Šé«˜éœ€è¦è¶Šå¤šçš„è¨˜æ†¶é«”ã€è¨“ç·´æ™‚é–“ã€æ¨¡å‹åƒæ•¸é‡ï¼Œæ­¤å¤–ï¼Œåœ¨è³‡æ–™ç§»å‹•ä¸Šä¹Ÿæœƒå¾ˆè²»åŠ›ã€‚
ç„¶è€Œåœ¨é«˜è§£æåº¦çš„ç…§ç‰‡ä¸­æœ‰è¨±å¤šåƒç´ éƒ½æ˜¯é‡è¤‡å€¼ï¼Œç•¶å¤§åˆ°ä¸€å®šç¨‹åº¦å¾Œæœƒå°æ¨¡å‹é æ¸¬å¹«åŠ©ä¸å¤§ï¼Œå¤ªé«˜ç”šè‡³æœƒå¹²æ“¾çµæœã€‚æ­¤å¤–ï¼Œæ¨¡å‹ä¹Ÿéœ€è¦é…åˆå»å¢åŠ éš±è—å±¤å’Œæ¨¡å‹è¤‡é›œåº¦æ‰èƒ½æœ‰æ•ˆå»å­¸ç¿’é«˜è§£æåº¦çš„åœ–ç‰‡ã€‚
å› æ­¤ï¼Œåœ¨åˆå§‹è§£æåº¦å¤§å°ä¸Šï¼Œæˆ‘å€‘çµ±ä¸€å°‡åŸå§‹æœ€é«˜çš„ `2400 è¬åƒç´ `å£“ç¸® `200 è¬ç•«ç´ `å·¦å³ã€‚åŸå§‹è³‡æ–™ä¹Ÿå¾ `127 G` æ¸›å°‘åˆ° `32 G`ï¼Œæ–¹ä¾¿å¾ŒçºŒè³‡æ–™çš„è™•ç†èˆ‡æ¬ç§»ã€‚
![](doc/fig/resolution.png)

## 3. çµ±ä¸€è¼¸å…¥ç…§ç‰‡é•·å¯¬
ç…§ç‰‡éœ€è¦çµ±ä¸€å›ºå®šçš„å¤§å°æ‰èƒ½è¼¸å…¥åˆ°æ¨¡å‹ä¸­é€²è¡Œè¨“ç·´ï¼Œä¸»è¦çš„åšæ³•æœ‰`å‰ªè£(crop)`å’Œ`ç¸®æ”¾(resize)`ã€‚ä¸åŒçš„è™•ç†&å–æ¨£æ–¹å¼æœƒå½±éŸ¿æ¨¡å‹å­¸ç¿’çš„çµæœï¼Œå¦‚ä¸‹åœ–å°±æ˜¯ä»¥çµ±ä¸€å¤§å°çš„æ­£æ–¹å½¢å°ç…§ç‰‡åš `Crop`ï¼Œä»¥æ­¤ä½œç‚ºè¼¸å…¥ç‰¹å¾µã€‚
![](doc/fig/input_size.png)

## 4. ç…§ç‰‡è½‰å‘å•é¡Œ
åœ¨è³‡æ–™ä¸­æœ‰äº›åœ–ç‰‡å¯èƒ½æœƒæœ‰ç¿»è½‰çš„ç¾è±¡ï¼Œç•¶æŸäº›æ–¹å‘çš„ç…§ç‰‡å¤ªå°‘æœƒå°è‡´æ¨¡å‹ç„¡æ³•æœ‰æ•ˆè¾¨è­˜æœ‰è½‰å‘çš„ç…§ç‰‡ã€‚è™•ç†é€™å•é¡Œæœ‰å…©ç¨®æ–¹å‘ï¼Œä¸€æ˜¯åµæ¸¬éæ­£å‘çš„ç…§ç‰‡ä¸¦å°‡å…¶è½‰å›æ­£å¸¸æ–¹å‘ï¼ŒäºŒæ˜¯è®“æ¨¡å‹å­¸ç¿’ä¸åŒæ–¹å‘çš„ç…§ç‰‡ï¼Œä¹Ÿå°±æ˜¯è³‡æ–™å¢å¼·çš„æŠ€è¡“ã€‚åœ¨è³‡æ–™å¢å¼·ä¸Šä¸€èˆ¬çš„ä½œæ³•æ˜¯å°‡ä¸€å¼µç…§ç‰‡è¤‡è£½æˆå››å¼µåˆ†åˆ¥è½‰å‘ä¸åŒæ–¹å‘ã€‚ä½¿ç”¨ `torchvision.transforms.RandomRotation` æ–¹æ³•è®“æ¨¡å‹åœ¨è¨“ç·´éç¨‹ä¸­ï¼Œ dataloader æœƒéš¨æ©Ÿå°åœ–ç‰‡é€²è¡Œç¿»è½‰ï¼Œè®“æ¨¡å‹å¯ä»¥å­¸ç¿’åˆ°ä¸åŒæ–¹å‘çš„è³‡è¨Šã€‚
![](doc/fig/Rotation.png)

## 5. ç…§ç‰‡äº®åº¦ & è‰²å½©å·®ç•°
åœ¨è’é›†ç…§ç‰‡æ™‚å¯èƒ½æœƒå› ç‚ºå¤©æ°£ã€å…‰æºæˆ–æ˜¯è¨­å‚™ä¸Šçš„æˆåƒå·®ç•°å°è‡´æ¨¡å‹é›£ä»¥å°åœ–ç‰‡é€²è¡Œå­¸ç¿’ã€‚æ‰€ä»¥åœ–ç‰‡åšæ¨™æº–åŒ–æ˜¯å¾ˆé‡è¦çš„ä¸€å€‹æ­¥é©Ÿå› ç‚ºåœ–ç‰‡æ¨™æº–åŒ–å¯ä»¥é™ä½åœ¨å¯¦éš›æˆåƒä¸Šçš„å·®ç•°èˆ‡å¹²æ“¾ï¼Œè®“æ¨¡å‹å¯ä»¥æ›´å®¹æ˜“å»æ¯”è¼ƒç…§ç‰‡ä¸­çš„è³‡è¨Šã€‚åœ¨åœ–ç‰‡æ¨™æº–åŒ–çš„éƒ¨åˆ†ï¼Œæˆ‘å€‘ä½¿ç”¨ `torchvision.transforms.Normalize` å‡½å¼å°åœ–ç‰‡é€²è¡Œ `z-score normalization`ã€‚
![](doc/fig/brightness.png)

# Model used - CoAtNet
![](doc/image/Coatnet.png)
æ­¤æ¨¡å‹æ¶æ§‹ç”±CNNçµåˆTransformeræ”¹é€²è€Œä¾†ï¼Œå‚³çµ±CNNæ¶æ§‹è—‰ç”±æå–æ–¹å½¢ç¯„åœä¸­çš„ç‰¹å¾µå’Œå‰é¥‹ä¾†é€²è¡Œæ¨¡å‹å»ºæ§‹ï¼Œå……åˆ†åˆ©ç”¨äºŒç¶­åœ–å½¢å–®ä¸€ç¯„åœå…§åƒç´ ç›¸äº’é—œä¿‚ï¼Œä½†å°æ–¼åœ–å½¢å…¨åŸŸé—œè¯æ•æ„Ÿå°è¼ƒä½ï¼›Transformeræ¨¡å‹èˆ‡CNNç‰¹æ€§æ°å¥½ç›¸åï¼Œå°æ–¼å…¨åŸŸé—œè¯æ•æ„Ÿæ€§é«˜ï¼Œå°ç¯„åœä¸­é—œè¯æ•æ„Ÿæ€§ä½ï¼Œæ­¤æ¨¡å‹çµåˆå…©è€…çš„å„ªé»ï¼Œå°åœ–ç‰‡å…ˆåˆ©ç”¨CNNæå–å‡ºå±€éƒ¨ç‰¹å¾µï¼Œå†å‰é¥‹é€²å…¥Transformeræ¨¡å‹ã€‚

_è«–æ–‡é€£çµ: https://arxiv.org/abs/2106.04803_

# Experiment Result
## environment
åœ¨æ¨¡å‹åƒæ•¸ä¸Šå› æ™‚é–“èˆ‡æ•ˆèƒ½é™åˆ¶ä½¿ç”¨åŸä½œè€…é è¨­çš„æ¨¡å‹ã€‚åœ¨è¨“ç·´ç’°å¢ƒä¸‹ï¼Œå› ç‚ºæ²’é¡¯å¡é‹ç®—è³‡æºï¼Œæ‰€ä»¥ kaggle æä¾›çš„ GPU(Tesla P100-PCIE-16GB)ã€‚ç„¶è€Œåœ¨ kaggle ä¸Šæœ‰ä¸€å€‹ session æœ‰12 å°æ™‚çš„é™åˆ¶ï¼Œæ‰€ä»¥æˆ‘å€‘å°‡æ¨¡å‹è¼¸å…¥é™åˆ¶åœ¨ç…§ç‰‡å¤§å°é™åˆ¶åœ¨ 224x244ï¼Œé€™æ¨£å°±å¯ä»¥åœ¨æ™‚é–“å…§è·‘å®Œ 25 epochã€‚
åœ¨è³‡æ–™é›†ä¸Šå°‡è³‡æ–™åˆ‡åˆ†æˆ train(0.7)ã€val(0.1)ã€test(0.2)è¨“ç·´æ™‚æœƒä½¿ç”¨ train è³‡æ–™é€²å…¥æ¨¡å‹é€²è¡Œè¨“ç·´ï¼Œæ¯å€‹ epoch æœƒä½¿ç”¨ val è³‡æ–™é€²è¡Œé©—è­‰ï¼Œä¸¦ä¿ç•™ val çµæœæœ€å¥½çš„æ¨¡å‹
![](doc/image/training.png)


## EX1. æ¨£æœ¬æ•¸é‡
### result
![](doc/image/table1.png)

## EX2. Crop & Resize æ–¹å¼
![](doc/fig/crop-vs-resize_exp.png)
### result
![](doc/image/table2.png)


## EX3. Mask å¤©ç©º
![](doc/fig/sky_mask_exp.png)
### result
![](doc/image/table3.png)

## EX4. ç¶“ç·¯åº¦è³‡è¨Šçš„å°å…¥
![](doc/image/coordinate_info.png)
### result
æå‡ 2% å·¦å³

# Reproduce
## ğŸ“ Folder schema 
```
Crop-Image-Classification
    |-- data 

    |-- doc: ç›¸é—œæ–‡ä»¶

    |-- model: æ¨¡å‹

    |-- notebook: åˆ†æè¦–è¦ºåŒ–

    |-- output: è¼¸å‡ºå¯¦é©—çš„ log å’Œ model

    |-- scripts: shell or batch è…³æœ¬ï¼ŒåŒ…å«æ‰¹æ¬¡è·‘å¯¦é©—ã€è¨“ç·´ç¯„ä¾‹
        |- generate_dataset: å„å¯¦é©—ä½¿ç”¨ scripts/image_process.py ç”¢ç”Ÿè¨“ç·´è³‡æ–™
        |- train: ä½¿ç”¨ train.py è¨“ç·´è³‡æ–™çš„å¯¦é©—åƒæ•¸
        |-> check_image_size.py: æª¢æŸ¥åœ–ç‰‡å¤§å°
        |-> image_process.py: åœ–ç‰‡è™•ç†
        |-> download_file.sh: ä¸‹è¼‰ google drive è³‡æ–™
        |-> sort_exp_result.py: æ•´ç† train.py è¼¸å‡ºçš„å¯¦é©—çµæœ
    
    |-- utils

    |-> requirements.txt: python ä¾è³´å¥—ä»¶
    |-> train.py: ä¸»è¦è¨“ç·´ç¨‹å¼ç¢¼
    |-> LICENSE
    |-> README.md
```
## ğŸ–¥ï¸ Environment settings 
### `pytorch`
```shell
pip3 install torch torchvision torchaudio --extra-index-url https://download.pytorch.org/whl/cu116
```
- å¦‚ä½¿ç”¨ä¸åŒç’°å¢ƒè«‹åˆ° [pytorch å®˜ç¶²](https://pytorch.org/) é¸æ“‡å°æ‡‰ç‰ˆçš„æŒ‡ä»¤ã€‚

### `other packages`
```shell
pip3 install -r requirements.txt
```

## ğŸ™‹ Quick start 
é€™éƒ¨åˆ†ä½¿ç”¨å°æ¨£æœ¬çš„è³‡æ–™ï¼Œçµæœåƒ…ä¾›åƒè€ƒ
### `Step1: Clone ç¨‹å¼ç¢¼`
```shell
git clone https://github.com/aaron1aaron2/Crop-Image-Classification.git
cd Crop-Image-Classification
```

### `Step2: è³‡æ–™æº–å‚™`
#### ä¸‹è¼‰æ¸¬è©¦è³‡æ–™
```shell
source scripts/download_file.sh "1ew3d6llpvj7ev1CssUbxiZ3FcANFRaOW&" "sample100_L160(test)" "data/sample100_L160(test)"
```

ä¹Ÿå¯ä»¥ç›´æ¥åˆ° [Google drive](https://drive.google.com/uc?id=1ew3d6llpvj7ev1CssUbxiZ3FcANFRaOW&confirm=t) ä¸‹è¼‰ï¼Œä¸¦è§£å£“ç¸®åˆ° _data/sample100_L160(test)_ åº•ä¸‹ã€‚

#### `or`
#### ç”¢ç”Ÿè¨“ç·´è³‡æ–™
```shell
python scripts/image_process.py
```


### `Step3: é–‹å§‹è¨“ç·´`
```shell
python train.py
```

# Citation
```bibtex
@article{dai2021coatnet,
  title={CoAtNet: Marrying Convolution and Attention for All Data Sizes},
  author={Dai, Zihang and Liu, Hanxiao and Le, Quoc V and Tan, Mingxing},
  journal={arXiv preprint arXiv:2106.04803},
  year={2021}
}
```

# Credits

Code adapted from [CoAtNet](https://github.com/chinhsuanwu/coatnet-pytorch)
